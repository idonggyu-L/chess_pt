{
  "act_dim": 4672,
  "activation_final": "none",
  "activations": "relu",
  "balance": false,
  "batch_size": 128,
  "clip_action": 0.999,
  "comment": "group_expert_intermediate_Blitz",
  "data_dir": "/home/hail/PreferenceTransformer/human_label/",
  "data_seed": 5,
  "data_size": 30000,
  "early_stop": true,
  "enable_bootstrap": false,
  "env": "chess",
  "eval_period": 1,
  "feedback_random": false,
  "feedback_uniform": false,
  "len_query": 50,
  "logging.anonymous": null,
  "logging.entity": "hails",
  "logging.experiment_id": null,
  "logging.group": null,
  "logging.notes": null,
  "logging.online": true,
  "logging.output_dir": "./reward_model",
  "logging.prefix": "",
  "logging.project": "Chess_pt",
  "logging.random_delay": 0.0,
  "max_traj_length": 1000,
  "min_delta": 0.005,
  "model_type": "PrefTransformer",
  "n_epochs": 1000,
  "num_query": 30000,
  "obs_dim": 1344,
  "orthogonal_init": false,
  "patience": 10,
  "query_len": 50,
  "reward.optimizer_type": "adam",
  "reward.rf_lr": 0.0003,
  "reward_arch": "256-256",
  "reward_bias": 0.0,
  "reward_scale": 1.0,
  "save_model": true,
  "seed": 5,
  "skip_flag": 0,
  "topk": 10,
  "training": true,
  "transformer.attn_pdrop": 0.1,
  "transformer.embd_dim": 128,
  "transformer.n_embd": 128,
  "transformer.n_head": 4,
  "transformer.n_layer": 4,
  "transformer.n_positions": 1024,
  "transformer.optimizer_type": "adamw",
  "transformer.pref_attn_embd_dim": 128,
  "transformer.resid_pdrop": 0.1,
  "transformer.scheduler_type": "CosineDecay",
  "transformer.train_type": "mean",
  "transformer.trans_lr": 0.0001,
  "transformer.use_weighted_sum": true,
  "transformer.vocab_size": 1,
  "use_human_label": true,
  "window": 2
}